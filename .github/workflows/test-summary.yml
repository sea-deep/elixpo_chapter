name: Test Summary with AI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

permissions:
  contents: read
  pull-requests: write
  checks: write

jobs:
  test-and-summarize:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install jq
        run: |
          if ! command -v jq &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y jq
          fi

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install only dev dependencies (no heavy models)
          pip install -r requirements-dev.txt

      - name: Run tests with coverage
        id: tests
        continue-on-error: true
        run: |
          # Skip tests if no test files exist, just report status
          if [ ! -d "tests" ] || [ -z "$(find tests -name 'test_*.py' -type f)" ]; then
            echo "No tests found - skipping test execution" > test_output.txt
            echo "exit_code=0" >> $GITHUB_OUTPUT
          else
            pytest tests/ --cov=. --cov-report=term --cov-report=json -v > test_output.txt 2>&1 || true
            echo "exit_code=$?" >> $GITHUB_OUTPUT
          fi
          cat test_output.txt

      - name: Get test results
        id: results
        run: |
          TEST_OUTPUT=$(cat test_output.txt)
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$TEST_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          if [ -f coverage.json ]; then
            COVERAGE=$(jq -r '.totals.percent_covered' coverage.json)
            echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          else
            echo "coverage=0" >> $GITHUB_OUTPUT
          fi

      - name: AI Test Summary
        id: summary
        run: |
          PROJECT_CONTEXT=$(cat .github/PROJECT_CONTEXT.md)
          
          PROMPT="You are analyzing test results for Memory-Arc, a Python memory management system.

          PROJECT CONTEXT:
          $PROJECT_CONTEXT

          Test Results:
          ${{ steps.results.outputs.output }}

          Coverage: ${{ steps.results.outputs.coverage }}%
          Exit Code: ${{ steps.tests.outputs.exit_code }}

          Provide a concise summary with:
          1. **Status**: Pass/Fail with emoji
          2. **Coverage**: Analysis of ${{ steps.results.outputs.coverage }}%
          3. **Key Findings**: Important test results
          4. **Recommendations**: If tests failed, suggest fixes
          5. **Next Steps**: What should be done

          Keep it brief and actionable. Use emojis and markdown formatting."

          SUMMARY=$(curl -s -X POST "https://text.pollinations.ai/openai" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${{ secrets.POLLI_TOKEN }}" \
            -d "{
              \"model\": \"gemini\",
              \"messages\": [{\"role\": \"user\", \"content\": $(echo "$PROMPT" | jq -Rs .)}],
              \"temperature\": 0.3,
              \"max_tokens\": 800
            }" | jq -r '.choices[0].message.content')

          echo "summary<<EOF" >> $GITHUB_OUTPUT
          echo "$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post Summary to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const summaryText = process.env.SUMMARY_TEXT;
            const testOutput = process.env.TEST_OUTPUT;
            const coverage = process.env.COVERAGE;
            
            const summary = `## üß™ Test Results Summary

            ${summaryText}

            <details>
            <summary>üìä Detailed Test Output</summary>

            \`\`\`
            ${testOutput}
            \`\`\`

            </details>

            ---
            *Generated by AI ‚Ä¢ Coverage: ${coverage}%*
            `;

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
        env:
          SUMMARY_TEXT: ${{ steps.summary.outputs.summary }}
          TEST_OUTPUT: ${{ steps.results.outputs.output }}
          COVERAGE: ${{ steps.results.outputs.coverage }}

      - name: Create Check Run
        uses: actions/github-script@v6
        with:
          script: |
            const exitCode = process.env.EXIT_CODE;
            const conclusion = exitCode === '0' ? 'success' : 'failure';
            const summaryText = process.env.SUMMARY_TEXT;
            const coverage = process.env.COVERAGE;
            
            await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'AI Test Summary',
              head_sha: context.sha,
              status: 'completed',
              conclusion: conclusion,
              output: {
                title: conclusion === 'success' ? '‚úÖ Tests Passed' : '‚ùå Tests Failed',
                summary: summaryText,
                text: `Coverage: ${coverage}%`
              }
            });
        env:
          EXIT_CODE: ${{ steps.tests.outputs.exit_code }}
          SUMMARY_TEXT: ${{ steps.summary.outputs.summary }}
          COVERAGE: ${{ steps.results.outputs.coverage }}
